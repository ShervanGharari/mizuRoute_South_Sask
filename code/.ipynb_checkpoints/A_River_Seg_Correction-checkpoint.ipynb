{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section 1 load all the necessary modules and packages\n",
    "import glob\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from shapely.geometry import Polygon\n",
    "# not neccessary for the function but for visualziation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "import networkx as nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining the most downstream river segment and lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the target river segment\n",
    "target_segment = 71021602 # segment that passes Saskatoon\n",
    "\n",
    "# load merti hydro river and catchments\n",
    "input_river = '/Users/shg096/Desktop/MERIT_Hydro/riv/riv_pfaf_71_MERIT_Hydro_v07_Basins_v01_bugfix1.shp'\n",
    "input_cat   = '/Users/shg096/Desktop/MERIT_Hydro/cat_final/cat_pfaf_71_MERIT_Hydro_v07_Basins_v01_bugfix1_fixed.shp'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset the river segment for a given outlet for MERIT hydro\n",
    "## South Saskatchewan River in Saskatoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          COMID   lengthkm  lengthdir  sinuosity     slope      uparea  order  \\\n",
      "0      71000001   7.020492   4.158236   1.688334  0.000570  391.901537      2   \n",
      "1      71000002  24.171249  15.709184   1.538670  0.000058  701.754912      2   \n",
      "2      71000003  14.760464  11.209022   1.316838  0.000770  480.760660      2   \n",
      "3      71000004   6.240078   4.631999   1.347168  0.000911  388.938962      2   \n",
      "4      71000005   4.462477   3.338111   1.336827  0.000670  328.557527      2   \n",
      "...         ...        ...        ...        ...       ...         ...    ...   \n",
      "48946  71048947   1.498642   1.192443   1.256782  0.000333   32.277067      1   \n",
      "48947  71048948   2.743329   1.941526   1.412975  0.001674   52.472792      1   \n",
      "48948  71048949   9.357690   5.642147   1.658534  0.000171   76.116685      1   \n",
      "48949  71048950  12.016268   9.919203   1.211415  0.001511   43.278839      1   \n",
      "48950  71048951  16.905509   8.524814   1.983094  0.000845   69.279829      1   \n",
      "\n",
      "       strmDrop_t  slope_taud  NextDownID  maxup       up1       up2  up3  \\\n",
      "0             0.0    0.000000    71000065      2  71000095  71000213    0   \n",
      "1             1.4    0.000058    71000065      2  71000003  71000014    0   \n",
      "2            11.4    0.000770    71000002      2  71000004  71000011    0   \n",
      "3             5.7    0.000911    71000003      2  71000005  71000015    0   \n",
      "4             3.0    0.000670    71000004      2  71000006  71000012    0   \n",
      "...           ...         ...         ...    ...       ...       ...  ...   \n",
      "48946         0.5    0.000333    71048442      0         0         0    0   \n",
      "48947         4.6    0.001674    71048857      0         0         0    0   \n",
      "48948         1.6    0.000171    71048338      0         0         0    0   \n",
      "48949        18.2    0.001511    71048880      0         0         0    0   \n",
      "48950        14.3    0.000845    71048401      0         0         0    0   \n",
      "\n",
      "       up4                                           geometry  \n",
      "0        0  LINESTRING (-98.06167 60.00000, -98.06250 59.9...  \n",
      "1        0  LINESTRING (-98.06167 60.00000, -98.06083 60.0...  \n",
      "2        0  LINESTRING (-98.17250 60.13000, -98.17333 60.1...  \n",
      "3        0  LINESTRING (-98.33500 60.07000, -98.33583 60.0...  \n",
      "4        0  LINESTRING (-98.39917 60.09667, -98.40000 60.0...  \n",
      "...    ...                                                ...  \n",
      "48946    0  LINESTRING (-96.79000 45.95583, -96.79083 45.9...  \n",
      "48947    0  LINESTRING (-96.90500 45.95500, -96.90583 45.9...  \n",
      "48948    0  LINESTRING (-97.72083 45.99500, -97.72000 45.9...  \n",
      "48949    0  LINESTRING (-96.25667 45.96417, -96.25583 45.9...  \n",
      "48950    0  LINESTRING (-96.57333 45.99417, -96.57417 45.9...  \n",
      "\n",
      "[48951 rows x 16 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_ID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/b1qy7zb96k980mcb2ps9n6d9t1c6zr/T/ipykernel_96492/1172718287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mancestors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mriv_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_ID' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the files and calculating the downstream of each segment\n",
    "riv  = gpd.read_file(input_river)\n",
    "cat  = gpd.read_file(input_cat)\n",
    "\n",
    "print(riv)\n",
    "\n",
    "\n",
    "\n",
    "# get all the upstream\n",
    "# create the riv graph\n",
    "riv_graph = nx.from_pandas_edgelist(riv,\\\n",
    "                                    source='COMID',\\\n",
    "                                    target='NextDownID',\\\n",
    "                                    create_using=nx.DiGraph)\n",
    "nodes = nx.ancestors(riv_graph, target_segment)\n",
    "nodes = np.array(list(nodes))\n",
    "nodes = np.append(nodes, target_segment)\n",
    "\n",
    "\n",
    "# subset\n",
    "cat_up = cat.loc[cat['COMID'].isin(nodes)]\n",
    "riv_up = riv.loc[riv['COMID'].isin(nodes)]\n",
    "# plotting\n",
    "cat_up.plot()\n",
    "riv_up.plot()\n",
    "\n",
    "ll\n",
    "\n",
    "# check the length\n",
    "if len(cat_up) == len(riv_up):\n",
    "    print('the element of the upstream segments and catchemtns do no match')\n",
    "# saving\n",
    "cat_up['cat_area'] = cat_up['unitarea'] * 1000000 # km2 to m2\n",
    "cat_up['cat_id'] = cat_up['COMID'] # cat_id\n",
    "cat_up = cat_up.drop(columns=['unitarea', 'COMID']) # drop COMID and unitarea\n",
    "cat_up.to_file('../shp/cat_'+str(target_segment)+'.shp')\n",
    "# saving river\n",
    "riv_up['length']    = riv_up['lengthkm'] * 1000 # km to m\n",
    "riv_up['seg_id']    = riv_up['COMID'] # COMID to seg_id\n",
    "riv_up['to_seg_id'] = riv_up['NextDownID'] # NextDownID to to_seg_id\n",
    "riv_up['uparea']    = riv_up['uparea'] * 1000000 # km2 to m2\n",
    "idx = riv_up.index[riv_up['seg_id']==target_segment]\n",
    "# down ID is not in the seg_id\n",
    "riv_up['to_seg_id'].loc[idx] = -9999 # this should be more general, -9999 for all the points where the \n",
    "riv_up.to_file('../shp/riv_'+str(target_segment)+'.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset the hydrolake based on the bounding box of the catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/b1qy7zb96k980mcb2ps9n6d9t1c6zr/T/ipykernel_38077/2022927573.py:8: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lake['x'] = lake.centroid.x # add centroid lon\n",
      "/var/folders/yh/b1qy7zb96k980mcb2ps9n6d9t1c6zr/T/ipykernel_38077/2022927573.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  lake['y'] = lake.centroid.y # add centroid lat\n",
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'Polygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "# read the hydrolakes shapefile\n",
    "lake = gpd.read_file('/Volumes/F:/hydrography/hydrolakes/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10_shp/HydroLAKES_polys_v10.shp')\n",
    "cat_up = gpd.read_file('../shp/cat_'+str(target_segment)+'.shp')\n",
    "lake['lake_id'] = lake['Hylak_id'] # lake ID\n",
    "lake['Lake_area'] = lake['Lake_area'] * 1000000 # km2 to m2\n",
    "lake['lake_vol'] = lake['Vol_total'] * 1000000 # million m3 to m3\n",
    "lake = lake.rename(columns={'Lake_area':'lake_area'})\n",
    "lake['x'] = lake.centroid.x # add centroid lon\n",
    "lake['y'] = lake.centroid.y # add centroid lat\n",
    "# boundaries\n",
    "min_lon, min_lat, max_lon, max_lat = cat_up.total_bounds\n",
    "min_lon, min_lat, max_lon, max_lat = min_lon-2, min_lat-2, max_lon+2, max_lat+2 # add two degree buffer\n",
    "# subset lake\n",
    "lake_subset = lake\n",
    "lake_subset = lake_subset[lake_subset['x']<max_lon]\n",
    "lake_subset = lake_subset[lake_subset['x']>min_lon]\n",
    "lake_subset = lake_subset[lake_subset['y']<max_lat]\n",
    "lake_subset = lake_subset[lake_subset['y']>min_lat]\n",
    "lake_subset.to_file('../shp/lake_'+str(target_segment)+'.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## intersection of river segment and lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiLineString'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "lake = gpd.read_file('../shp/lake_'+str(target_segment)+'.shp')\n",
    "riv_up = gpd.read_file('../shp/riv_'+str(target_segment)+'.shp')\n",
    "river_int_lake = gpd.overlay(riv_up, lake, how = 'intersection')\n",
    "river_int_lake.to_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if the intersection seg_id has unique lake_id\n",
    "## otherwise dissolving is needed for seg_id and lake_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it seems there is one seg_id for each element of the river and lake intersection\n"
     ]
    }
   ],
   "source": [
    "# read the intersected shapefile of river network and \n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "not_unique = False\n",
    "\n",
    "for i in np.unique(shp['seg_id']):\n",
    "    shp_sub = shp[shp['seg_id'] == i] # subset the river segment elements\n",
    "    if len(np.unique(shp_sub['lake_id'])) != len(shp_sub['lake_id']): # segment intersect with more than 1 lake\n",
    "        not_unique = True\n",
    "\n",
    "# reporting\n",
    "if not_unique:\n",
    "    print('it seems there are less seg_id that elements of the river and lake intersection;')\n",
    "    print('river and lake intersection should be dissolved on seg_id and lake_id')\n",
    "else:\n",
    "    print('it seems there is one seg_id for each element of the river and lake intersection')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the number of lakes that a segment is interseting with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lakes in the intersection: 471\n",
      "number of river segments that intersect with more than one lake : 124\n"
     ]
    }
   ],
   "source": [
    "# read the intersected shapefile of river network and \n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "print('Number of lakes in the intersection:',len(np.unique(shp['lake_id'])))\n",
    "m = 0\n",
    "for i in np.unique(shp['seg_id']):\n",
    "    shp_sub = shp[shp['seg_id'] == i] # subset the river segment elements\n",
    "    if len(np.unique(shp_sub['lake_id'])) > 1: # segment intersect with more than 1 lake\n",
    "        m = m + 1 # counter\n",
    "#         print(i) # print the segment ID\n",
    "#         print('number of lakes: ',len(np.unique(shp_sub['lake_id']))) # print the number of lake\n",
    "#         print('number of lakes: ',(np.unique(shp_sub['lake_id']))) # print lake ID\n",
    "#         print('----')\n",
    "# num seg intersecting with more than 1 lake\n",
    "print('number of river segments that intersect with more than one lake :', m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify the intersection step 1\n",
    "\n",
    "### Remove the smaller lakes for river segments that have more than one lake intersecting with them in the river_intersection_lake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lakes in the original intersection: 471\n",
      "Number of lakes in the simplified intersection: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiLineString'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "# read the intersected shapefile of river network and \n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "lake_ID = np.unique(shp['lake_id']) # get the ID of the lakes in teh intersetion\n",
    "print('Number of lakes in the original intersection:',len(np.unique(shp['lake_id'])))\n",
    "shp['remove'] = 0 # initializing the remove field\n",
    "\n",
    "# looping over the segments, and remove the multiple lakes based on the area\n",
    "warnings.simplefilter('ignore') # silent the warning\n",
    "for i in np.unique(shp['seg_id']):\n",
    "    shp_sub = shp[shp['seg_id'] == i] # subset based on river segments\n",
    "    if len(np.unique(shp_sub['lake_id'])) > 1: # segment intersect with more than 1 lake\n",
    "        # print(i) # print segment ID\n",
    "        shp_sub = shp_sub.sort_values(by = ['lake_area'], ascending=False) # sort based on lake area\n",
    "        max_lake_area = shp_sub['lake_area'].max() # get the maximume lake area\n",
    "        for index, row in shp_sub.iterrows():\n",
    "            if shp['lake_area'].loc[index] != max_lake_area:\n",
    "                shp['remove'].loc[index] = 1 # loop over the subset shapefile and remove lake with smaller area\n",
    "warnings.simplefilter('default') # back to normal\n",
    "\n",
    "shp = shp [shp['remove']==1] # remove lakes which are flagged to be removed\n",
    "shp = shp.sort_values(by= 'seg_id') # sort based on seg_id\n",
    "shp = shp.reset_index(drop=True) # reindex based on the new sorting\n",
    "\n",
    "#get the lake ID of the removed object\n",
    "lake_ID_remove = np.unique(shp['lake_id']) # the IDs that are removed\n",
    "lake_ID_keep = np.setdiff1d(lake_ID, lake_ID_remove) # the IDs that should be kept\n",
    "\n",
    "# subset the intersection based on the lake_ID that are kept\n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "shp = shp[shp['lake_id'].isin(lake_ID_keep)] # subset the shapefile to IDs that are kept\n",
    "print('Number of lakes in the simplified intersection:',len(np.unique(shp['lake_id']))) # print the number\n",
    "shp.to_file('../shp/riv_lake_'+str(target_segment)+'.shp') # save to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify the intersection step 2\n",
    "### Remove the lakes that have only on river segment passing through them (unresolved lakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lakes in the simplified intersection: 297\n",
      "Number of lakes in the simplified intersection: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiLineString'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp') # read from file\n",
    "print('Number of lakes in the simplified intersection:',len(np.unique(shp['lake_id'])))\n",
    "# remove the lakes that have only one river segment (unresolvabale lakes)\n",
    "shp['keep'] = 1\n",
    "\n",
    "# looping over lakes and take out the lake that has only one river segment \n",
    "warnings.simplefilter('ignore') # silent the warning\n",
    "for i in np.unique(shp['lake_id']):\n",
    "    # print(i)\n",
    "    shp_sub = shp[shp['lake_id'] == i] # subset the river segment inside a lake\n",
    "    if len(np.unique(shp_sub['seg_id'])) == 1:\n",
    "        indx = shp_sub.index\n",
    "        shp['keep'].loc[indx] = 0\n",
    "warnings.simplefilter('default') # back to normal\n",
    "\n",
    "shp = shp [shp['keep']==1]\n",
    "shp = shp.sort_values(by= 'seg_id')\n",
    "shp = shp.reset_index(drop=True)\n",
    "\n",
    "print('Number of lakes in the simplified intersection:',len(np.unique(shp['lake_id'])))\n",
    "shp.to_file('../shp/riv_lake_'+str(target_segment)+'.shp') # save to file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the simplified result\n",
    "### To reassure that the simplified intersection has one lake per segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lakes in the intersection: 70\n",
      "number of river segments that intersect with more than one lake : 0\n",
      "good to continue\n"
     ]
    }
   ],
   "source": [
    "# read the intersected shapefile of river network and \n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "print('Number of lakes in the intersection:',len(np.unique(shp['lake_id'])))\n",
    "m = 0\n",
    "for i in np.unique(shp['seg_id']):\n",
    "    shp_sub = shp[shp['seg_id'] == i] # subset the river segment elements\n",
    "    if len(np.unique(shp_sub['lake_id'])) > 1: # segment intersect with more than 1 lake\n",
    "        m = m + 1 # counter\n",
    "        print(i) # print the segment ID\n",
    "        print('number of lakes: ',len(np.unique(shp_sub['lake_id']))) # print the number of lake\n",
    "        print('number of lakes: ',(np.unique(shp_sub['lake_id']))) # print lake ID\n",
    "        print('----')\n",
    "# num seg intersecting with more than 1 lake\n",
    "print('number of river segments that intersect with more than one lake :', m)\n",
    "if m == 0:\n",
    "    print('good to continue')\n",
    "else:\n",
    "    print('sth is wrong! the number of lake river intersection')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check if the intersection seg_id has unique lake_id\n",
    "## otherwise dissolving is needed for seg_id and lake_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it seems there is one seg_id for each element of the river and lake intersection\n",
      "good to go\n"
     ]
    }
   ],
   "source": [
    "# read the intersected shapefile of river network and \n",
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "not_unique = False\n",
    "\n",
    "for i in np.unique(shp['seg_id']):\n",
    "    shp_sub = shp[shp['seg_id'] == i] # subset the river segment elements\n",
    "    if len(np.unique(shp_sub['lake_id'])) != len(shp_sub['lake_id']): # segment intersect with more than 1 lake\n",
    "        not_unique = True\n",
    "\n",
    "# reporting\n",
    "if not_unique:\n",
    "    print('it seems there are less seg_id that elements of the river and lake intersection;')\n",
    "    print('river and lake intersection should be dissolved on seg_id and lake_id')\n",
    "else:\n",
    "    print('it seems there is one seg_id for each element of the river and lake intersection')\n",
    "    print('good to go')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resolved lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'Polygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "lake = gpd.read_file('../shp/lake_'+str(target_segment)+'.shp')\n",
    "resolved_lake_id = np.unique(shp['lake_id'])\n",
    "lake_resolved = lake[lake['lake_id'].isin(resolved_lake_id)]\n",
    "lake_resolved.to_file('../shp/resolved_lake_'+str(target_segment)+'.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify the outflow and inflow for the river segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiLineString'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "shp = gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "\n",
    "shp ['inflow'] = 1\n",
    "shp ['outflow'] = 0\n",
    "\n",
    "warnings.simplefilter('ignore') # silent the warning\n",
    "for i in np.unique(shp['lake_id']):\n",
    "    # print(i)\n",
    "    shp_sub = shp[shp['lake_id'] == i] # subset the river segment inside a lake\n",
    "    max_area = shp_sub['uparea'].max()\n",
    "    indexs = shp_sub.index\n",
    "    for index in indexs:\n",
    "        if (shp_sub['uparea'].loc[index] == max_area) and (shp_sub['to_seg_id'].loc[index] > 0):\n",
    "            shp ['inflow'].loc[index] = 0\n",
    "            shp ['outflow'].loc[index] = 1\n",
    "warnings.simplefilter('default') # silent the warning\n",
    "\n",
    "shp.to_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the length based on what is under the lake\n",
    "### Here the length is corrected for the segments that have a link with the lake (the simplified version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "riv_lake =  gpd.read_file('../shp/riv_lake_'+str(target_segment)+'.shp')\n",
    "riv      =  gpd.read_file('../shp/riv_'+str(target_segment)+'.shp')\n",
    "\n",
    "# reproect to meter projection and prepare the field to allocated\n",
    "riv_lake_temp = riv_lake.to_crs (\"EPSG:6933\") # project to equal area\n",
    "riv_lake ['length_lake'] = riv_lake_temp.length\n",
    "riv_lake = riv_lake.sort_values(by='seg_id')\n",
    "riv_lake = riv_lake.reset_index(drop=True)\n",
    "\n",
    "# riv length_ratio and subset for riv_lake_simplified\n",
    "riv_temp = riv.to_crs (\"EPSG:6933\")\n",
    "riv['length_bef'] = riv_temp.length\n",
    "riv_sub = riv[riv['seg_id'].isin(np.array(riv_lake['seg_id']))]\n",
    "riv_sub = riv_sub.sort_values(by='seg_id')\n",
    "riv_sub = riv_sub.reset_index(drop=True)\n",
    "\n",
    "# riv \n",
    "riv_sub['len_ratio'] = 1.00 - (riv_lake['length_lake']/riv_sub['length_bef'])\n",
    "riv_sub['inflow'] = riv_lake['inflow']\n",
    "riv_sub['outflow'] = riv_lake['outflow']\n",
    "riv_sub['lake_id'] = riv_lake['lake_id']\n",
    "\n",
    "# default values\n",
    "riv['len_ratio'] = 1.00\n",
    "riv['inflow'] = -1.00\n",
    "riv['outflow'] = -1.00\n",
    "riv['lake_id'] = -1.00\n",
    "# pass the values to the riv shapefile\n",
    "indx = riv.index[riv['seg_id'].isin(riv_sub['seg_id'])]\n",
    "riv['len_ratio'].loc[indx] = np.array(riv_sub['len_ratio'])\n",
    "riv['inflow'].loc[indx] = np.array(riv_sub['inflow'])\n",
    "riv['outflow'].loc[indx] = np.array(riv_sub['outflow'])\n",
    "riv['lake_id'].loc[indx] = np.array(riv_sub['lake_id'])\n",
    "\n",
    "riv.to_file('../shp/riv_lake_length_corrected_'+str(target_segment)+'.shp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correcting the subbasins for lakes and find their area ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:1638: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiPolygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  result[:] = values\n",
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/pandas/core/dtypes/cast.py:1638: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'Polygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  result[:] = values\n",
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'MultiPolygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n",
      "/Users/shg096/opt/anaconda3/envs/myenv38/lib/python3.8/site-packages/geopandas/_vectorized.py:150: DeprecationWarning: An exception was ignored while fetching the attribute `__array_interface__` from an object of type 'Polygon'.  With the exception of `AttributeError` NumPy will always raise this exception in the future.  Raise this deprecation warning to see the original exception. (Warning added NumPy 1.21)\n",
      "  out[:] = [_pygeos_to_shapely(geom) for geom in data]\n"
     ]
    }
   ],
   "source": [
    "lakes = gpd.read_file('../shp/resolved_lake_'+str(target_segment)+'.shp')\n",
    "basins = gpd.read_file('../shp/cat_'+str(target_segment)+'.shp')\n",
    "\n",
    "# calculate the area of cat with equal area\n",
    "basins_temp = basins.to_crs(\"EPSG:6933\")\n",
    "basins ['area_bef'] = basins_temp.area # calculated area before correction\n",
    "\n",
    "# correcting the basins based on the lakes\n",
    "basin_corrected = gpd.overlay(basins,lakes, how='difference')\n",
    "\n",
    "# calculate the area of cat after lake correction\n",
    "basin_corrected_temp = basin_corrected.to_crs (\"EPSG:6933\")\n",
    "basin_corrected['area_aft'] = basin_corrected_temp.area # caclualted area after correction\n",
    "\n",
    "# calculate area_ratio and corrected area\n",
    "basin_corrected['area_ratio'] = basin_corrected['area_aft']/basin_corrected['area_bef']\n",
    "basin_corrected = basin_corrected.drop(columns=['area_bef', 'area_aft'])\n",
    "basin_corrected ['is_lake'] = 0.00\n",
    "\n",
    "# make lake the same units as the \n",
    "lakes ['cat_area'] = lakes ['lake_area']\n",
    "lakes ['cat_id'] = lakes ['lake_id']\n",
    "lakes ['is_lake'] = 1.00\n",
    "lakes ['area_ratio'] = 1.00\n",
    "\n",
    "basin_corrected = basin_corrected.append(lakes)\n",
    "\n",
    "basin_corrected = basin_corrected.filter(['cat_area','cat_id','is_lake','area_ratio','geometry'])\n",
    "\n",
    "basin_corrected.to_file('../shp/cat_lake_area_corrected_'+str(target_segment)+'.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv38",
   "language": "python",
   "name": "myenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
